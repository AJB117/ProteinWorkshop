# @package _global_

# === 1. Set config parameters ===
name: "sequence_struct" # default name for the experiment, "" means logger (eg. wandb) will generate a unique name
seed: 52 # seed for random number generators in pytorch, numpy and python.random
num_workers: 16 # number of subprocesses to use for data loading.

# === 2. Specify defaults here. Defaults will be overwritten by equivalently named options in this file ===
defaults:
  - env: default
  - dataset: ec_reaction
  - features: all_invariant_ca
  - encoder: sequence_struct_interactor
  - decoder: default
  - transforms: default
  - optimiser: adam
  - trainer: gpu
  - extras: default
  - hydra: default
  - metrics: none
  - task: multiclass_graph_classification
  - logger: csv # Also supported: tensorboard, wandb
  # debugging config (enable through command line, e.g. `python train.py debug=default)
  - debug: null
  - _self_ # see: https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order/. Adding _self_ at bottom means values in this file override defaults.

callbacks:
  early_stopping:
    monitor: val/graph_label/accuracy
    mode: "max"
  model_checkpoint:
    monitor: val/graph_label/accuracy
    mode: "max"

  scheduler:
    values: [plateau]

  # task:
  #   values: [binary_graph_classification]

trainer:
  accelerator: gpu
  devices: 1 # debuggers don't like multiprocessing
  detect_anomaly: true # raise exception if NaN or +/-inf is detected in any tensor
  max_epochs: 500

precision: 16

task_name: "train"
test: False
#compile: True
